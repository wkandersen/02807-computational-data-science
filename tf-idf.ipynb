{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "793a9121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song 0 top terms: [('times', 0.5), ('thousand', 0.5), ('hello', 0.5), ('called', 0.5)]\n",
      "Song 1 top terms: [('sunshine', 0.5286346066596935), ('ll', 0.5286346066596935), ('s', 0.5286346066596935), ('life', 0.4020402441612698)]\n",
      "Song 2 top terms: [('reality', 0.3632547094545769), ('real', 0.3632547094545769), ('caught', 0.3632547094545769), ('fantasy', 0.3632547094545769), ('escape', 0.3632547094545769)]\n",
      "Global top terms: [('Is', 0.5877677203306594), ('life', 0.5789387184958397), ('You', 0.4673509818107163), (\"I'll\", 0.4673509818107163), ('sunshine', 0.4673509818107163), (\"that's\", 0.4673509818107163), ('thousand', 0.4472135954999579), ('times', 0.4472135954999579), ('called', 0.4472135954999579), ('Hello', 0.4472135954999579)]\n"
     ]
    }
   ],
   "source": [
    "# from tfidf_songs import get_top_tfidf_words, get_global_top_words\n",
    "\n",
    "from typing import List, Tuple, Optional\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\"\"\"\n",
    "tfidf_songs.py\n",
    "\n",
    "Simple TF-IDF utilities to extract important words from a list of song lyrics (or any documents).\n",
    "\n",
    "Usage:\n",
    "\n",
    "    songs = [\n",
    "        \"Hello from the other side I must have called a thousand times\",\n",
    "        \"You are the sunshine of my life that's why I'll always be around\",\n",
    "        \"Is this the real life? Is this just fantasy?\"\n",
    "    ]\n",
    "\n",
    "    per_song = get_top_tfidf_words(songs, top_n=5)\n",
    "    global_top = get_global_top_words(songs, top_n=10)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def get_top_tfidf_words(\n",
    "    docs: List[str],\n",
    "    top_n: int = 10,\n",
    "    max_features: Optional[int] = None,\n",
    "    stop_words: Optional[str] = \"english\",\n",
    ") -> List[List[Tuple[str, float]]]:\n",
    "    \"\"\"\n",
    "    Compute TF-IDF on the provided documents and return top_n words (token, score)\n",
    "    for each document sorted by descending TF-IDF score.\n",
    "\n",
    "    Parameters:\n",
    "        docs: list of strings (songs / lyrics)\n",
    "        top_n: number of top words to return per document\n",
    "        max_features: if set, limits the vocabulary to the top max_features by term frequency\n",
    "        stop_words: stop word strategy passed to TfidfVectorizer (e.g., 'english' or None)\n",
    "\n",
    "    Returns:\n",
    "        List (per document) of lists of (term, score) tuples.\n",
    "    \"\"\"\n",
    "    if not docs:\n",
    "        return []\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        stop_words=stop_words,\n",
    "        max_features=max_features,\n",
    "        lowercase=True,\n",
    "        token_pattern=r\"(?u)\\b\\w+\\b\",\n",
    "    )\n",
    "    X = vectorizer.fit_transform(docs)  # shape (n_docs, n_terms)\n",
    "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "\n",
    "    results: List[List[Tuple[str, float]]] = []\n",
    "    for row in X:\n",
    "        if row.nnz == 0:\n",
    "            results.append([])\n",
    "            continue\n",
    "        # convert to dense array of scores for this doc\n",
    "        scores = row.toarray().ravel()\n",
    "        # get indices of top_n scores\n",
    "        top_indices = np.argsort(scores)[::-1][:top_n]\n",
    "        top_terms_scores = [(feature_names[i], float(scores[i])) for i in top_indices if scores[i] > 0]\n",
    "        results.append(top_terms_scores)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_global_top_words(\n",
    "    docs: List[str],\n",
    "    top_n: int = 20,\n",
    "    max_features: Optional[int] = None,\n",
    "    stop_words: Optional[str] = \"english\",\n",
    ") -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Compute TF-IDF across the corpus and return the top_n terms by summed TF-IDF score\n",
    "    across all documents.\n",
    "\n",
    "    Returns:\n",
    "        List of (term, summed_score) tuples sorted by descending score.\n",
    "    \"\"\"\n",
    "    if not docs:\n",
    "        return []\n",
    "\n",
    "    def _preprocessor(text: str) -> str:\n",
    "        # normalize typographic apostrophes to ASCII so contractions like \"don't\" are preserved\n",
    "        return text.replace(\"’\", \"'\")\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        preprocessor=_preprocessor,\n",
    "        stop_words=stop_words,\n",
    "        max_features=max_features,\n",
    "        lowercase=True,\n",
    "        token_pattern=r\"(?u)\\b\\w[\\w']*\\b\",\n",
    "    )\n",
    "    X = vectorizer.fit_transform(docs)  # shape (n_docs, n_terms)\n",
    "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "\n",
    "    # sum TF-IDF scores across documents for each term\n",
    "    summed = np.array(X.sum(axis=0)).ravel()\n",
    "    top_indices = np.argsort(summed)[::-1][:top_n]\n",
    "    return [(feature_names[i], float(summed[i])) for i in top_indices if summed[i] > 0]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # quick demo\n",
    "    sample_songs = [\n",
    "        \"Hello from the other side I must have called a thousand times\",\n",
    "        \"You are the sunshine of my life that's why I'll always be around\",\n",
    "        \"Is this the real life? Is this just fantasy? Caught in a landslide, no escape from reality\",\n",
    "    ]\n",
    "\n",
    "    per_song = get_top_tfidf_words(sample_songs, top_n=5)\n",
    "    for i, terms in enumerate(per_song):\n",
    "        print(f\"Song {i} top terms:\", terms)\n",
    "\n",
    "    print(\"Global top terms:\", get_global_top_words(sample_songs, top_n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd4d3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top hiphop words: [('ooh', 3.8692211355713857), ('oh', 2.9725899579404467), (\"can't\", 2.87465594418233), ('beautiful', 2.6275725371059133), ('rockabye', 2.4464611375147527), ('just', 1.9607577069057704), ('wanna', 1.8179535649443692), (\"i'm\", 1.809518500998487), ('shake', 1.7197039580162896), ('lost', 1.6446797270120272), ('love', 1.574973621906904), (\"won't\", 1.5480378373948658), (\"you're\", 1.501162100640595), ('minutes', 1.4824172321817546), ('fikki', 1.4824172321817546), ('baby', 1.4360396943880591), ('middle', 1.3424825824669855), ('vs', 1.3387822050670577), (\"don't\", 1.3320349553919502), ('gonna', 1.278367730170045), ('yeah', 1.2334279388881664), ('mind', 1.1449007055834177), ('got', 1.1431915334593075), ('time', 1.1313452762964327), ('moment', 1.1255709693704612), ('tick', 1.111812924136316), ('tock', 1.111812924136316), ('like', 1.0748043695927918), ('say', 1.036269489962364), ('feel', 1.0348910315143796)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# the most distinct words within the dancepop genre\n",
    "\n",
    "df = pd.read_csv('billboard_24years_lyrics_spotify_with_genres.csv')  # Assuming a CSV file with a 'lyrics' column\n",
    "\n",
    "# get hiphop genre\n",
    "\n",
    "hiphop_lyrics = df[df['genre'] == 'dancepop']['lyrics'].dropna().str.lower().tolist()\n",
    "\n",
    "top_hiphop_words = get_global_top_words(hiphop_lyrics, top_n=30)\n",
    "\n",
    "print(\"Top hiphop words:\", top_hiphop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9b567716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from typing import List, Tuple\n",
    "\n",
    "def get_genre_distinctive_emotion_words(\n",
    "    df: pd.DataFrame,\n",
    "    df_emo: pd.DataFrame,\n",
    "    genre: str,\n",
    "    top_n: int = 30,\n",
    "    stop_words: str = \"english\"\n",
    ") -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Compute words that are distinctive for a given genre compared to all other genres,\n",
    "    restricting to words in the NRC Emotion Lexicon.\n",
    "\n",
    "    Parameters:\n",
    "        df: pandas DataFrame with 'lyrics' and 'genre' columns\n",
    "        df_emo: pandas DataFrame with 'word' column from NRC Emotion Lexicon\n",
    "        genre: target genre\n",
    "        top_n: number of top words to return\n",
    "        stop_words: stop word strategy for TfidfVectorizer\n",
    "\n",
    "    Returns:\n",
    "        List of (word, score) tuples sorted by descending distinctiveness\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert NRC words to a set for fast lookup\n",
    "    emo_words_set = set(df_emo['word'])\n",
    "\n",
    "    # Filter lyrics\n",
    "    genre_lyrics = df[df['genre'] == genre]['lyrics'].dropna().str.lower().tolist()\n",
    "    other_lyrics = df[df['genre'] != genre]['lyrics'].dropna().str.lower().tolist()\n",
    "\n",
    "    all_lyrics = genre_lyrics + other_lyrics\n",
    "\n",
    "    # Fit TF-IDF\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        stop_words=stop_words,\n",
    "        lowercase=True,\n",
    "        token_pattern=r\"(?u)\\b\\w[\\w']*\\b\"\n",
    "    )\n",
    "    X = vectorizer.fit_transform(all_lyrics)\n",
    "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "\n",
    "    # Split TF-IDF matrix\n",
    "    X_genre = X[:len(genre_lyrics), :]\n",
    "    X_other = X[len(genre_lyrics):, :]\n",
    "\n",
    "    # Sum TF-IDF scores\n",
    "    tfidf_genre_sum = np.array(X_genre.sum(axis=0)).ravel()\n",
    "    tfidf_other_sum = np.array(X_other.sum(axis=0)).ravel()\n",
    "\n",
    "    # Distinctiveness score\n",
    "    distinctive_score = tfidf_genre_sum - tfidf_other_sum\n",
    "\n",
    "    # Keep only words that are in the NRC lexicon\n",
    "    top_indices = np.argsort(distinctive_score)[::-1]\n",
    "    top_words = []\n",
    "    for i in top_indices:\n",
    "        word = feature_names[i]\n",
    "        score = float(distinctive_score[i])\n",
    "        if score > 0 and word in emo_words_set:\n",
    "            top_words.append((word, score))\n",
    "        if len(top_words) >= top_n:\n",
    "            break\n",
    "\n",
    "    return top_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "18779bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top distinctive emotion words for hip-hop: [('tumble', 0.531447436039241), ('fumble', 0.531447436039241), ('frost', 0.41950263964362866), ('awaken', 0.4103245144802319), ('villain', 0.4002840656021327), ('toby', 0.2679213290691669), ('nickel', 0.26695195872800437), ('kris', 0.26529471046284614), ('pow', 0.2511493187479352), ('convertible', 0.22792690744888117), ('snack', 0.22377851133050092), ('noisy', 0.21575951138728724), ('revive', 0.19367663799300366), ('repent', 0.19282259893886605), ('mogul', 0.19261285800528402), ('bowls', 0.19261285800528402), ('multiple', 0.19261285800528402), ('fender', 0.17714914534641366), ('vertical', 0.17714914534641366), ('nebula', 0.17714914534641366), ('casket', 0.17360414571353844), ('dab', 0.17182115163914397), ('deacon', 0.171716323976964), ('nodding', 0.171716323976964), ('craps', 0.171716323976964), ('niece', 0.171716323976964), ('adobe', 0.168714882240808), ('fountain', 0.16482433809656005), ('shaken', 0.16370259785417882), ('tart', 0.16344934745220688)]\n"
     ]
    }
   ],
   "source": [
    "# the most distinct words within the hiphop genre compared to all other genres, restricted to emotion words\n",
    "df_songs = pd.read_csv('billboard_24years_lyrics_spotify_with_genres.csv')\n",
    "df_emo = pd.read_csv(\n",
    "    'NRC-Emotion-Lexicon-Wordlevel-v0.92.txt',\n",
    "    sep='\\t',\n",
    "    header=None,\n",
    "    names=['word', 'emotion', 'association']\n",
    ")\n",
    "\n",
    "# Get top distinctive emotion words for a genre\n",
    "top_dancepop_emotion_words = get_genre_distinctive_emotion_words(\n",
    "    df_songs,\n",
    "    df_emo,\n",
    "    genre='trap',\n",
    "    top_n=30\n",
    ")\n",
    "\n",
    "print(\"Top distinctive emotion words for hip-hop:\", top_dancepop_emotion_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8d86511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "def map_song_to_emotions_count(song_lyrics: str, df_emo: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Map words in a song's lyrics to emotions and count frequency.\n",
    "    Returns a dictionary: emotion -> count of words\n",
    "    \"\"\"\n",
    "    # Prepare mapping: word -> list of emotions\n",
    "    word_to_emotions = defaultdict(list)\n",
    "    for _, row in df_emo.iterrows():\n",
    "        word_to_emotions[row['word']].append(row['emotion'])\n",
    "\n",
    "    # Tokenize lyrics\n",
    "    words = song_lyrics.lower().split()\n",
    "\n",
    "    # Count occurrences of each emotion\n",
    "    emotion_counts = Counter()\n",
    "    for word in words:\n",
    "        if word in word_to_emotions:\n",
    "            for emotion in word_to_emotions[word]:\n",
    "                emotion_counts[emotion] += 1\n",
    "\n",
    "    return dict(emotion_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f82549a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion counts for the song: {'anger': 3, 'anticipation': 3, 'joy': 8, 'positive': 13, 'surprise': 4, 'trust': 9, 'negative': 16, 'fear': 3, 'sadness': 3, 'disgust': 2}\n"
     ]
    }
   ],
   "source": [
    "df_emo_ones = df_emo[df_emo['association'] == 1]\n",
    "example_lyrics = df_songs['lyrics'][1]  # first song\n",
    "emotion_counts = map_song_to_emotions_count(example_lyrics, df_emo_ones)\n",
    "\n",
    "print(\"Emotion counts for the song:\", emotion_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b529ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply your mapping function to each song's lyrics\n",
    "# emotion_dicts = df_songs['lyrics'].apply(lambda lyrics: map_song_to_emotions_count(lyrics, df_emo_ones))\n",
    "\n",
    "# # Convert list of dicts into a DataFrame\n",
    "# df_emotions = pd.DataFrame(list(emotion_dicts))\n",
    "\n",
    "# # Fill missing values with 0 (if some emotions are absent in a song)\n",
    "# df_emotions = df_emotions.fillna(0)\n",
    "\n",
    "# # Add emotion columns to the original songs DataFrame\n",
    "# df_songs_with_emotions = pd.concat([df_songs, df_emotions], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4000ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# --- Your function, modified to accept pre-built word_to_emotions dict ---\n",
    "def map_song_to_emotions_count(song_lyrics: str, word_to_emotions: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Map words in a song's lyrics to emotions and count frequency.\n",
    "    Returns a dictionary: emotion -> count of words\n",
    "    \"\"\"\n",
    "    words = song_lyrics.lower().split()\n",
    "    emotion_counts = Counter()\n",
    "    for word in words:\n",
    "        if word in word_to_emotions:\n",
    "            for emotion in word_to_emotions[word]:\n",
    "                emotion_counts[emotion] += 1\n",
    "    return dict(emotion_counts)\n",
    "\n",
    "# --- Main execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Filter emotions with association == 1\n",
    "    df_emo_ones = df_emo[df_emo['association'] == 1]\n",
    "\n",
    "    # Step 2: Pre-build word -> emotion mapping\n",
    "    word_to_emotions = defaultdict(list)\n",
    "    for _, row in df_emo_ones.iterrows():\n",
    "        word_to_emotions[row['word']].append(row['emotion'])\n",
    "\n",
    "    # Step 3: Prepare song lyrics list\n",
    "    songs_lyrics = df_songs['lyrics'].tolist()\n",
    "\n",
    "    # Step 4: Define worker for multiprocessing\n",
    "    def worker_map_song(lyrics):\n",
    "        return map_song_to_emotions_count(lyrics, word_to_emotions)\n",
    "\n",
    "    # Step 5: Parallel MapReduce-style processing\n",
    "    n_workers = cpu_count()\n",
    "    with Pool(n_workers) as pool:\n",
    "        emotion_dicts = pool.map(worker_map_song, songs_lyrics)\n",
    "\n",
    "    # Step 6: Convert list of dicts to DataFrame and combine\n",
    "    df_emotions = pd.DataFrame(emotion_dicts).fillna(0)\n",
    "    df_songs_with_emotions = pd.concat([df_songs.reset_index(drop=True), df_emotions.reset_index(drop=True)], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "44defbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>positive</th>\n",
       "      <th>trust</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>negative</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2step garage, r&amp;b</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acoustic hiphop</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afrobeats</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afrobeats, pop, r&amp;b, reggae</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afrobeats, r&amp;b</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>6.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>worldbeat</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>worldbeat, latin pop, pop rock</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>| recorded =</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>|length =</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>|length = 2:47</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>944 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              genre  anticipation       fear        joy  \\\n",
       "0                 2step garage, r&b     10.000000   2.000000   6.000000   \n",
       "1                   acoustic hiphop      0.000000   2.000000   1.000000   \n",
       "2                         afrobeats      8.333333   7.666667  11.333333   \n",
       "3       afrobeats, pop, r&b, reggae      7.000000   5.000000  10.000000   \n",
       "4                    afrobeats, r&b      5.000000   7.333333  11.666667   \n",
       "..                              ...           ...        ...        ...   \n",
       "939                       worldbeat      9.000000  10.000000  12.000000   \n",
       "940  worldbeat, latin pop, pop rock      3.000000   2.000000  10.000000   \n",
       "941                    | recorded =      7.666667   2.000000   4.333333   \n",
       "942                       |length =      2.000000   6.000000   1.000000   \n",
       "943                  |length = 2:47      0.000000   0.000000   4.000000   \n",
       "\n",
       "      positive      trust     anger    disgust   negative    sadness  surprise  \n",
       "0    14.000000  19.000000  2.000000   0.000000  10.000000   4.000000  3.000000  \n",
       "1     1.000000   1.000000  2.000000   1.000000   6.000000   1.000000  0.000000  \n",
       "2    21.333333   9.333333  5.666667   5.666667  13.333333   9.000000  5.666667  \n",
       "3    20.000000  12.000000  3.000000   3.000000   4.000000   5.000000  1.000000  \n",
       "4    15.000000   5.666667  6.333333   5.666667  13.333333   8.333333  6.333333  \n",
       "..         ...        ...       ...        ...        ...        ...       ...  \n",
       "939  13.000000  11.000000  9.000000   9.000000  10.000000  10.000000  6.000000  \n",
       "940  20.000000   4.000000  2.000000   1.000000  10.000000   4.000000  6.000000  \n",
       "941   7.666667   6.000000  2.000000   2.000000   6.333333   7.000000  4.333333  \n",
       "942   1.000000   3.000000  2.000000   0.000000  10.000000   6.000000  0.000000  \n",
       "943   6.000000   1.000000  3.000000  18.000000  19.000000   1.000000  0.000000  \n",
       "\n",
       "[944 rows x 11 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of emotion columns\n",
    "emotion_cols = ['anticipation','fear','joy','positive','trust',\n",
    "                'anger','disgust','negative','sadness','surprise']\n",
    "\n",
    "# Include 'genre' column\n",
    "cols_to_use = ['genre'] + emotion_cols\n",
    "df_emotions_genre = df_songs_with_emotions[cols_to_use]\n",
    "\n",
    "# Group by genre and compute mean for each emotion\n",
    "df_genre_emotions_mean = df_emotions_genre.groupby('genre').mean().reset_index()\n",
    "\n",
    "df_genre_emotions_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp_tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

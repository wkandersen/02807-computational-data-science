{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "793a9121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song 0 top terms: [('times', 0.5), ('thousand', 0.5), ('hello', 0.5), ('called', 0.5)]\n",
      "Song 1 top terms: [('sunshine', 0.5286346066596935), ('ll', 0.5286346066596935), ('s', 0.5286346066596935), ('life', 0.4020402441612698)]\n",
      "Song 2 top terms: [('reality', 0.3632547094545769), ('real', 0.3632547094545769), ('caught', 0.3632547094545769), ('fantasy', 0.3632547094545769), ('escape', 0.3632547094545769)]\n",
      "Global top terms: [('Is', 0.5877677203306594), ('life', 0.5789387184958397), ('You', 0.4673509818107163), (\"I'll\", 0.4673509818107163), ('sunshine', 0.4673509818107163), (\"that's\", 0.4673509818107163), ('thousand', 0.4472135954999579), ('times', 0.4472135954999579), ('called', 0.4472135954999579), ('Hello', 0.4472135954999579)]\n"
     ]
    }
   ],
   "source": [
    "# from tfidf_songs import get_top_tfidf_words, get_global_top_words\n",
    "\n",
    "from typing import List, Tuple, Optional\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\"\"\"\n",
    "tfidf_songs.py\n",
    "\n",
    "Simple TF-IDF utilities to extract important words from a list of song lyrics (or any documents).\n",
    "\n",
    "Usage:\n",
    "\n",
    "    songs = [\n",
    "        \"Hello from the other side I must have called a thousand times\",\n",
    "        \"You are the sunshine of my life that's why I'll always be around\",\n",
    "        \"Is this the real life? Is this just fantasy?\"\n",
    "    ]\n",
    "\n",
    "    per_song = get_top_tfidf_words(songs, top_n=5)\n",
    "    global_top = get_global_top_words(songs, top_n=10)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def get_top_tfidf_words(\n",
    "    docs: List[str],\n",
    "    top_n: int = 10,\n",
    "    max_features: Optional[int] = None,\n",
    "    stop_words: Optional[str] = \"english\",\n",
    ") -> List[List[Tuple[str, float]]]:\n",
    "    \"\"\"\n",
    "    Compute TF-IDF on the provided documents and return top_n words (token, score)\n",
    "    for each document sorted by descending TF-IDF score.\n",
    "\n",
    "    Parameters:\n",
    "        docs: list of strings (songs / lyrics)\n",
    "        top_n: number of top words to return per document\n",
    "        max_features: if set, limits the vocabulary to the top max_features by term frequency\n",
    "        stop_words: stop word strategy passed to TfidfVectorizer (e.g., 'english' or None)\n",
    "\n",
    "    Returns:\n",
    "        List (per document) of lists of (term, score) tuples.\n",
    "    \"\"\"\n",
    "    if not docs:\n",
    "        return []\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        stop_words=stop_words,\n",
    "        max_features=max_features,\n",
    "        lowercase=True,\n",
    "        token_pattern=r\"(?u)\\b\\w+\\b\",\n",
    "    )\n",
    "    X = vectorizer.fit_transform(docs)  # shape (n_docs, n_terms)\n",
    "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "\n",
    "    results: List[List[Tuple[str, float]]] = []\n",
    "    for row in X:\n",
    "        if row.nnz == 0:\n",
    "            results.append([])\n",
    "            continue\n",
    "        # convert to dense array of scores for this doc\n",
    "        scores = row.toarray().ravel()\n",
    "        # get indices of top_n scores\n",
    "        top_indices = np.argsort(scores)[::-1][:top_n]\n",
    "        top_terms_scores = [(feature_names[i], float(scores[i])) for i in top_indices if scores[i] > 0]\n",
    "        results.append(top_terms_scores)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_global_top_words(\n",
    "    docs: List[str],\n",
    "    top_n: int = 20,\n",
    "    max_features: Optional[int] = None,\n",
    "    stop_words: Optional[str] = \"english\",\n",
    ") -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Compute TF-IDF across the corpus and return the top_n terms by summed TF-IDF score\n",
    "    across all documents.\n",
    "\n",
    "    Returns:\n",
    "        List of (term, summed_score) tuples sorted by descending score.\n",
    "    \"\"\"\n",
    "    if not docs:\n",
    "        return []\n",
    "\n",
    "    def _preprocessor(text: str) -> str:\n",
    "        # normalize typographic apostrophes to ASCII so contractions like \"don't\" are preserved\n",
    "        return text.replace(\"â€™\", \"'\")\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        preprocessor=_preprocessor,\n",
    "        stop_words=stop_words,\n",
    "        max_features=max_features,\n",
    "        lowercase=True,\n",
    "        token_pattern=r\"(?u)\\b\\w[\\w']*\\b\",\n",
    "    )\n",
    "    X = vectorizer.fit_transform(docs)  # shape (n_docs, n_terms)\n",
    "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "\n",
    "    # sum TF-IDF scores across documents for each term\n",
    "    summed = np.array(X.sum(axis=0)).ravel()\n",
    "    top_indices = np.argsort(summed)[::-1][:top_n]\n",
    "    return [(feature_names[i], float(summed[i])) for i in top_indices if summed[i] > 0]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # quick demo\n",
    "    sample_songs = [\n",
    "        \"Hello from the other side I must have called a thousand times\",\n",
    "        \"You are the sunshine of my life that's why I'll always be around\",\n",
    "        \"Is this the real life? Is this just fantasy? Caught in a landslide, no escape from reality\",\n",
    "    ]\n",
    "\n",
    "    per_song = get_top_tfidf_words(sample_songs, top_n=5)\n",
    "    for i, terms in enumerate(per_song):\n",
    "        print(f\"Song {i} top terms:\", terms)\n",
    "\n",
    "    print(\"Global top terms:\", get_global_top_words(sample_songs, top_n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd4d3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top hiphop words: [('ooh', 3.8692211355713853), ('oh', 2.972589957940446), (\"can't\", 2.8746559441823303), ('beautiful', 2.627572537105913), ('rockabye', 2.4464611375147522), ('just', 1.9607577069057711), ('wanna', 1.8179535649443688), (\"i'm\", 1.8095185009984873), ('shake', 1.7197039580162896), ('lost', 1.6446797270120272), ('love', 1.574973621906904), (\"won't\", 1.5480378373948653), (\"you're\", 1.5011621006405946), ('minutes', 1.4824172321817546), ('fikki', 1.4824172321817546), ('baby', 1.4360396943880591), ('middle', 1.3424825824669857), ('vs', 1.3387822050670577), (\"don't\", 1.3320349553919508), ('gonna', 1.2783677301700447), ('yeah', 1.2334279388881662), ('mind', 1.1449007055834177), ('got', 1.1431915334593077), ('time', 1.1313452762964327), ('moment', 1.1255709693704612), ('tick', 1.1118129241363162), ('tock', 1.1118129241363162), ('like', 1.0748043695927918), ('say', 1.0362694899623635), ('feel', 1.0348910315143796)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# the most distinct words within the dancepop genre\n",
    "\n",
    "df = pd.read_csv('billboard_24years_lyrics_spotify_with_genres.csv')  # Assuming a CSV file with a 'lyrics' column\n",
    "\n",
    "# get hiphop genre\n",
    "\n",
    "hiphop_lyrics = df[df['genre'] == 'dancepop']['lyrics'].dropna().str.lower().tolist()\n",
    "\n",
    "top_hiphop_words = get_global_top_words(hiphop_lyrics, top_n=30)\n",
    "\n",
    "print(\"Top hiphop words:\", top_hiphop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b567716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from typing import List, Tuple\n",
    "\n",
    "def get_genre_distinctive_emotion_words(\n",
    "    df: pd.DataFrame,\n",
    "    df_emo: pd.DataFrame,\n",
    "    genre: str,\n",
    "    top_n: int = 30,\n",
    "    stop_words: str = \"english\"\n",
    ") -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Compute words that are distinctive for a given genre compared to all other genres,\n",
    "    restricting to words in the NRC Emotion Lexicon.\n",
    "\n",
    "    Parameters:\n",
    "        df: pandas DataFrame with 'lyrics' and 'genre' columns\n",
    "        df_emo: pandas DataFrame with 'word' column from NRC Emotion Lexicon\n",
    "        genre: target genre\n",
    "        top_n: number of top words to return\n",
    "        stop_words: stop word strategy for TfidfVectorizer\n",
    "\n",
    "    Returns:\n",
    "        List of (word, score) tuples sorted by descending distinctiveness\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert NRC words to a set for fast lookup\n",
    "    emo_words_set = set(df_emo['word'])\n",
    "\n",
    "    # Filter lyrics\n",
    "    genre_lyrics = df[df['genre'] == genre]['lyrics'].dropna().str.lower().tolist()\n",
    "    other_lyrics = df[df['genre'] != genre]['lyrics'].dropna().str.lower().tolist()\n",
    "\n",
    "    all_lyrics = genre_lyrics + other_lyrics\n",
    "\n",
    "    # Fit TF-IDF\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        stop_words=stop_words,\n",
    "        lowercase=True,\n",
    "        token_pattern=r\"(?u)\\b\\w[\\w']*\\b\"\n",
    "    )\n",
    "    X = vectorizer.fit_transform(all_lyrics)\n",
    "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "\n",
    "    # Split TF-IDF matrix\n",
    "    X_genre = X[:len(genre_lyrics), :]\n",
    "    X_other = X[len(genre_lyrics):, :]\n",
    "\n",
    "    # Sum TF-IDF scores\n",
    "    tfidf_genre_sum = np.array(X_genre.sum(axis=0)).ravel()\n",
    "    tfidf_other_sum = np.array(X_other.sum(axis=0)).ravel()\n",
    "\n",
    "    # Distinctiveness score\n",
    "    distinctive_score = tfidf_genre_sum - tfidf_other_sum\n",
    "\n",
    "    # Keep only words that are in the NRC lexicon\n",
    "    top_indices = np.argsort(distinctive_score)[::-1]\n",
    "    top_words = []\n",
    "    for i in top_indices:\n",
    "        word = feature_names[i]\n",
    "        score = float(distinctive_score[i])\n",
    "        if score > 0 and word in emo_words_set:\n",
    "            top_words.append((word, score))\n",
    "        if len(top_words) >= top_n:\n",
    "            break\n",
    "\n",
    "    return top_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18779bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top distinctive emotion words for hip-hop: [('tumble', 0.531447436039241), ('fumble', 0.531447436039241), ('frost', 0.41950263964362866), ('awaken', 0.4103245144802319), ('villain', 0.4002840656021327), ('toby', 0.2679213290691669), ('nickel', 0.26695195872800437), ('kris', 0.26529471046284614), ('pow', 0.2511493187479352), ('convertible', 0.22792690744888117), ('snack', 0.22377851133050092), ('noisy', 0.21575951138728724), ('revive', 0.19367663799300366), ('repent', 0.19282259893886605), ('mogul', 0.19261285800528402), ('bowls', 0.19261285800528402), ('multiple', 0.19261285800528402), ('fender', 0.17714914534641366), ('vertical', 0.17714914534641366), ('nebula', 0.17714914534641366), ('casket', 0.17360414571353844), ('dab', 0.17182115163914397), ('deacon', 0.171716323976964), ('nodding', 0.171716323976964), ('craps', 0.171716323976964), ('niece', 0.171716323976964), ('adobe', 0.168714882240808), ('fountain', 0.16482433809656005), ('shaken', 0.16370259785417882), ('tart', 0.16344934745220688)]\n"
     ]
    }
   ],
   "source": [
    "# the most distinct words within the hiphop genre compared to all other genres, restricted to emotion words\n",
    "df_songs = pd.read_csv('billboard_24years_lyrics_spotify_with_genres.csv')\n",
    "df_emo = pd.read_csv(\n",
    "    'NRC-Emotion-Lexicon-Wordlevel-v0.92.txt',\n",
    "    sep='\\t',\n",
    "    header=None,\n",
    "    names=['word', 'emotion', 'association']\n",
    ")\n",
    "\n",
    "# Get top distinctive emotion words for a genre\n",
    "top_dancepop_emotion_words = get_genre_distinctive_emotion_words(\n",
    "    df_songs,\n",
    "    df_emo,\n",
    "    genre='trap',\n",
    "    top_n=30\n",
    ")\n",
    "\n",
    "print(\"Top distinctive emotion words for hip-hop:\", top_dancepop_emotion_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8d86511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "def map_song_to_emotions_count(song_lyrics: str, df_emo: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Map words in a song's lyrics to emotions and count frequency.\n",
    "    Returns a dictionary: emotion -> count of words\n",
    "    \"\"\"\n",
    "    # Prepare mapping: word -> list of emotions\n",
    "    word_to_emotions = defaultdict(list)\n",
    "    for _, row in df_emo.iterrows():\n",
    "        word_to_emotions[row['word']].append(row['emotion'])\n",
    "\n",
    "    # Tokenize lyrics\n",
    "    words = song_lyrics.lower().split()\n",
    "    print(len(words))\n",
    "\n",
    "    # Count occurrences of each emotion\n",
    "    emotion_counts = Counter()\n",
    "    for word in words:\n",
    "        if word in word_to_emotions:\n",
    "            for emotion in word_to_emotions[word]:\n",
    "                emotion_counts[emotion] += 1\n",
    "\n",
    "    return dict(emotion_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82549a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366\n",
      "Emotion counts for the song: {'anger': 3, 'anticipation': 3, 'joy': 8, 'positive': 13, 'surprise': 4, 'trust': 9, 'negative': 16, 'fear': 3, 'sadness': 3, 'disgust': 2}\n"
     ]
    }
   ],
   "source": [
    "df_emo_ones = df_emo[df_emo['association'] == 1]\n",
    "example_lyrics = df_songs['lyrics'][1]  # first song\n",
    "emotion_counts = map_song_to_emotions_count(example_lyrics, df_emo_ones)\n",
    "\n",
    "print(\"Emotion counts for the song:\", emotion_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp_tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793a9121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song 0 top terms: [('times', 0.5), ('thousand', 0.5), ('hello', 0.5), ('called', 0.5)]\n",
      "Song 1 top terms: [('sunshine', 0.5286346066596935), ('ll', 0.5286346066596935), ('s', 0.5286346066596935), ('life', 0.4020402441612698)]\n",
      "Song 2 top terms: [('reality', 0.3632547094545769), ('real', 0.3632547094545769), ('caught', 0.3632547094545769), ('fantasy', 0.3632547094545769), ('escape', 0.3632547094545769)]\n",
      "Global top terms: [('Is', 0.5877677203306594), ('life', 0.5789387184958397), ('You', 0.4673509818107163), (\"I'll\", 0.4673509818107163), ('sunshine', 0.4673509818107163), (\"that's\", 0.4673509818107163), ('thousand', 0.4472135954999579), ('times', 0.4472135954999579), ('called', 0.4472135954999579), ('Hello', 0.4472135954999579)]\n"
     ]
    }
   ],
   "source": [
    "# from tfidf_songs import get_top_tfidf_words, get_global_top_words\n",
    "\n",
    "from typing import List, Tuple, Optional\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\"\"\"\n",
    "tfidf_songs.py\n",
    "\n",
    "Simple TF-IDF utilities to extract important words from a list of song lyrics (or any documents).\n",
    "\n",
    "Usage:\n",
    "\n",
    "    songs = [\n",
    "        \"Hello from the other side I must have called a thousand times\",\n",
    "        \"You are the sunshine of my life that's why I'll always be around\",\n",
    "        \"Is this the real life? Is this just fantasy?\"\n",
    "    ]\n",
    "\n",
    "    per_song = get_top_tfidf_words(songs, top_n=5)\n",
    "    global_top = get_global_top_words(songs, top_n=10)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def get_top_tfidf_words(\n",
    "    docs: List[str],\n",
    "    top_n: int = 10,\n",
    "    max_features: Optional[int] = None,\n",
    "    stop_words: Optional[str] = \"english\",\n",
    ") -> List[List[Tuple[str, float]]]:\n",
    "    \"\"\"\n",
    "    Compute TF-IDF on the provided documents and return top_n words (token, score)\n",
    "    for each document sorted by descending TF-IDF score.\n",
    "\n",
    "    Parameters:\n",
    "        docs: list of strings (songs / lyrics)\n",
    "        top_n: number of top words to return per document\n",
    "        max_features: if set, limits the vocabulary to the top max_features by term frequency\n",
    "        stop_words: stop word strategy passed to TfidfVectorizer (e.g., 'english' or None)\n",
    "\n",
    "    Returns:\n",
    "        List (per document) of lists of (term, score) tuples.\n",
    "    \"\"\"\n",
    "    if not docs:\n",
    "        return []\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        stop_words=stop_words,\n",
    "        max_features=max_features,\n",
    "        lowercase=True,\n",
    "        token_pattern=r\"(?u)\\b\\w+\\b\",\n",
    "    )\n",
    "    X = vectorizer.fit_transform(docs)  # shape (n_docs, n_terms)\n",
    "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "\n",
    "    results: List[List[Tuple[str, float]]] = []\n",
    "    for row in X:\n",
    "        if row.nnz == 0:\n",
    "            results.append([])\n",
    "            continue\n",
    "        # convert to dense array of scores for this doc\n",
    "        scores = row.toarray().ravel()\n",
    "        # get indices of top_n scores\n",
    "        top_indices = np.argsort(scores)[::-1][:top_n]\n",
    "        top_terms_scores = [(feature_names[i], float(scores[i])) for i in top_indices if scores[i] > 0]\n",
    "        results.append(top_terms_scores)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_global_top_words(\n",
    "    docs: List[str],\n",
    "    top_n: int = 20,\n",
    "    max_features: Optional[int] = None,\n",
    "    stop_words: Optional[str] = \"english\",\n",
    ") -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Compute TF-IDF across the corpus and return the top_n terms by summed TF-IDF score\n",
    "    across all documents.\n",
    "\n",
    "    Returns:\n",
    "        List of (term, summed_score) tuples sorted by descending score.\n",
    "    \"\"\"\n",
    "    if not docs:\n",
    "        return []\n",
    "\n",
    "    def _preprocessor(text: str) -> str:\n",
    "        # normalize typographic apostrophes to ASCII so contractions like \"don't\" are preserved\n",
    "        return text.replace(\"â€™\", \"'\")\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        preprocessor=_preprocessor,\n",
    "        stop_words=stop_words,\n",
    "        max_features=max_features,\n",
    "        lowercase=True,\n",
    "        token_pattern=r\"(?u)\\b\\w[\\w']*\\b\",\n",
    "    )\n",
    "    X = vectorizer.fit_transform(docs)  # shape (n_docs, n_terms)\n",
    "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "\n",
    "    # sum TF-IDF scores across documents for each term\n",
    "    summed = np.array(X.sum(axis=0)).ravel()\n",
    "    top_indices = np.argsort(summed)[::-1][:top_n]\n",
    "    return [(feature_names[i], float(summed[i])) for i in top_indices if summed[i] > 0]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # quick demo\n",
    "    sample_songs = [\n",
    "        \"Hello from the other side I must have called a thousand times\",\n",
    "        \"You are the sunshine of my life that's why I'll always be around\",\n",
    "        \"Is this the real life? Is this just fantasy? Caught in a landslide, no escape from reality\",\n",
    "    ]\n",
    "\n",
    "    per_song = get_top_tfidf_words(sample_songs, top_n=5)\n",
    "    for i, terms in enumerate(per_song):\n",
    "        print(f\"Song {i} top terms:\", terms)\n",
    "\n",
    "    print(\"Global top terms:\", get_global_top_words(sample_songs, top_n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffd4d3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top hiphop words: [('ooh', 3.8692211355713853), ('oh', 2.972589957940446), (\"can't\", 2.8746559441823303), ('beautiful', 2.627572537105913), ('rockabye', 2.4464611375147522), ('just', 1.9607577069057711), ('wanna', 1.8179535649443688), (\"i'm\", 1.8095185009984873), ('shake', 1.7197039580162896), ('lost', 1.6446797270120272), ('love', 1.574973621906904), (\"won't\", 1.5480378373948653), (\"you're\", 1.5011621006405946), ('minutes', 1.4824172321817546), ('fikki', 1.4824172321817546), ('baby', 1.4360396943880591), ('middle', 1.3424825824669857), ('vs', 1.3387822050670577), (\"don't\", 1.3320349553919508), ('gonna', 1.2783677301700447), ('yeah', 1.2334279388881662), ('mind', 1.1449007055834177), ('got', 1.1431915334593077), ('time', 1.1313452762964327), ('moment', 1.1255709693704612), ('tick', 1.1118129241363162), ('tock', 1.1118129241363162), ('like', 1.0748043695927918), ('say', 1.0362694899623635), ('feel', 1.0348910315143796)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('billboard_24years_lyrics_spotify_with_genres.csv')  # Assuming a CSV file with a 'lyrics' column\n",
    "\n",
    "# get hiphop genre\n",
    "\n",
    "hiphop_lyrics = df[df['genre'] == 'dancepop']['lyrics'].dropna().str.lower().tolist()\n",
    "\n",
    "top_hiphop_words = get_global_top_words(hiphop_lyrics, top_n=30)\n",
    "\n",
    "print(\"Top hiphop words:\", top_hiphop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "349e05f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ooh', 3.8692211355713853),\n",
       " ('oh', 2.972589957940446),\n",
       " (\"can't\", 2.8746559441823303),\n",
       " ('beautiful', 2.627572537105913),\n",
       " ('rockabye', 2.4464611375147522),\n",
       " ('just', 1.9607577069057711),\n",
       " ('wanna', 1.8179535649443688),\n",
       " (\"i'm\", 1.8095185009984873),\n",
       " ('shake', 1.7197039580162896),\n",
       " ('lost', 1.6446797270120272),\n",
       " ('love', 1.574973621906904),\n",
       " (\"won't\", 1.5480378373948653),\n",
       " (\"you're\", 1.5011621006405946),\n",
       " ('minutes', 1.4824172321817546),\n",
       " ('fikki', 1.4824172321817546),\n",
       " ('baby', 1.4360396943880591),\n",
       " ('middle', 1.3424825824669857),\n",
       " ('vs', 1.3387822050670577),\n",
       " (\"don't\", 1.3320349553919508),\n",
       " ('gonna', 1.2783677301700447),\n",
       " ('yeah', 1.2334279388881662),\n",
       " ('mind', 1.1449007055834177),\n",
       " ('got', 1.1431915334593077),\n",
       " ('time', 1.1313452762964327),\n",
       " ('moment', 1.1255709693704612),\n",
       " ('tick', 1.1118129241363162),\n",
       " ('tock', 1.1118129241363162),\n",
       " ('like', 1.0748043695927918),\n",
       " ('say', 1.0362694899623635),\n",
       " ('feel', 1.0348910315143796)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_hiphop_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer_vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
